# ğŸš— Cityscapes Semantic Segmentation

**High-performance semantic segmentation for autonomous driving** | Part of a multi-task perception system

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

---

## ğŸ“Š Current Performance

| Metric | Value | Notes |
|--------|-------|-------|
| **Val mIoU** | **66.62%** | Experiment 2.2 (640Ã—640 resolution) |
| **Val mIoU (TTA)** | **66.99%** | +0.99% with Test-Time Augmentation |
| **Train mIoU** | 75.03% | Slight overfitting (gap: 8.4%) |
| **Training Time** | ~6-8 hours | 150 epochs on RTX 2060 |

**From baseline 53% â†’ 66.6% val mIoU** (+13.6% improvement!)

---

## ğŸ¯ Features

- âœ… **DeepLabV3+ with EfficientNet-B3** encoder (ImageNet pretrained)
- âœ… **640Ã—640 resolution** for better ASPP context and small object detection
- âœ… **Joint Loss**: Focal Loss + Dice Loss for class imbalance handling
- âœ… **Moderate augmentation** (spatial + photometric transforms)
- âœ… **Test-Time Augmentation** (6x ensemble: 3 scales + h-flip)
- âœ… **Mixed precision training** (AMP) for memory efficiency
- âœ… **Cosine Annealing LR** with warm restarts
- âœ… **Progressive encoder unfreezing** for transfer learning
- âœ… **Comprehensive experiment tracking** in `experiment_log.txt`

---

## ğŸ§ª Experiment Journey

| Exp | Change | Train mIoU | Val mIoU | Gap | Result |
|-----|--------|-----------|----------|-----|--------|
| **Baseline** | - | 61.0% | 53.0% | 8.0% | - |
| 1.1 | Dropout 0.3 | 66.1% | 53.5% | 12.7% | âŒ Worse gap |
| 2.1 | Aggressive aug | 48.4% | 47.3% | 1.1% | âŒ Underfitting |
| **2.1b** | Moderate aug | 70.0% | 58.8% | 11.2% | âœ… +5.8% val |
| **2.2** | Resolution 640Ã—640 | **75.0%** | **66.6%** | 8.4% | âœ… **+13.6% val!** |
| **3.1** | TTA (inference) | 75.0% | **67.0%** | 8.0% | âœ… +1% boost |
| 3.2a | Cosine Annealing | _In progress_ | _TBD_ | _TBD_ | â³ Training |

**Key Insights:**
- Resolution increase (512â†’640) was the biggest win (+7.8% val mIoU)
- Moderate augmentation found the sweet spot (aggressive caused underfitting)
- TTA provides +1% without retraining (especially on small objects: motorcycle +3.67%)

See detailed analysis in [`experiment_log.txt`](experiment_log.txt)

---

## ğŸš€ Quick Start

### Installation

```bash
# Clone repository
git clone <your-repo-url>
cd Semantic_Segmentation_Cityscapes

# Create virtual environment
python -m venv venv
venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux/Mac

# Install dependencies
pip install -r requirements.txt
```

### Dataset Setup

Download [Cityscapes dataset](https://www.cityscapes-dataset.com/) and update `config.py`:

```python
DATA_DIR = Path(r"C:\datasets\Cityspaces\images")
MASK_DIR = Path(r"C:\datasets\Cityspaces\gtFine")
```

Expected structure:
```
Cityspaces/
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ train/
â”‚   â””â”€â”€ val/
â””â”€â”€ gtFine/
    â”œâ”€â”€ train/
    â””â”€â”€ val/
```

### Training

```bash
# Train from scratch
python train.py

# Resume training (set RESUME=True in config.py)
python train.py
```

### Validation with TTA

```bash
# Test-Time Augmentation validation
python validate_tta.py
```

---

## ğŸ“ Project Structure

```
cityscapes-perception/
â”œâ”€â”€ config.py                   # Hyperparameters & paths
â”œâ”€â”€ train.py                    # Training script
â”œâ”€â”€ validate_tta.py            # TTA validation
â”œâ”€â”€ experiment_log.txt         # Detailed experiment tracking
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ dataset.py             # Cityscapes data loader
â”‚   â”œâ”€â”€ models.py              # DeepLabV3+ / UNet / MANet
â”‚   â”œâ”€â”€ losses.py              # Focal + Dice loss
â”‚   â”œâ”€â”€ metrics.py             # mIoU calculation
â”‚   â”œâ”€â”€ utils.py               # Checkpointing, visualization
â”‚   â””â”€â”€ tta.py                 # Test-Time Augmentation
â”œâ”€â”€ checkpoints/               # Model weights
â””â”€â”€ plots/                     # Training curves
```

---

## âš™ï¸ Configuration

Key settings in [`config.py`](config.py):

```python
# Model
MODEL_TYPE = "deeplabv3plus"
ENCODER = "efficientnet-b3"
DROPOUT = 0.2

# Training
BATCH_SIZE = 4
GRADIENT_ACCUMULATION_STEPS = 4  # Effective batch = 16
NUM_EPOCHS = 150
LEARNING_RATE = 5e-5

# Loss
DICE_LOSS_WEIGHT = 1.1
FOCAL_LOSS_WEIGHT = 2.0

# Data
RESIZE = False  # Use full 640Ã—640 resolution
CACHE = False   # Set True if you have 32GB+ RAM
```

---

## ğŸ› ï¸ Hardware Requirements

**Minimum:**
- GPU: NVIDIA GTX 1060 6GB
- RAM: 16GB
- Storage: 50GB (for Cityscapes)

**Tested on:**
- GPU: RTX 2060 6GB
- CPU: Intel i5-8400
- RAM: 32GB
- OS: Windows 11

---

## ğŸ“ˆ Technical Details

### Architecture
- **Backbone**: EfficientNet-B3 (ImageNet pretrained)
- **Decoder**: DeepLabV3+ with ASPP (Atrous Spatial Pyramid Pooling)
- **Input**: 640Ã—640 crops from 2048Ã—1024 Cityscapes images
- **Output**: 19-class pixel-wise predictions

### Loss Function
```
L_total = Focal(Î³=2.0, weight=2.0) + Dice(weight=1.1)
```
- **Focal Loss**: Handles class imbalance by focusing on hard examples
- **Dice Loss**: Optimizes IoU directly

### Data Augmentation
```python
# Training (moderate)
- RandomCrop 640Ã—640
- HorizontalFlip (p=0.5)
- ShiftScaleRotate (Â±10Â°, 0.9-1.1x scale, p=0.3)
- ColorJitter (brightness, contrast, saturation, hue)
- Light blur (motion/gaussian, p=0.1)

# Validation
- CenterCrop 640Ã—640
- Normalize (ImageNet stats)
```

### Training Strategy
1. **Progressive unfreezing**: Encoder frozen for first 7 epochs
2. **Cosine annealing**: LR restarts every 30 epochs
3. **Mixed precision**: AMP for memory efficiency
4. **Early stopping**: Patience of 50 epochs

---

## ğŸ—ºï¸ Roadmap

### Phase 1: Segmentation âœ…
- [x] Baseline DeepLabV3+ (53% mIoU)
- [x] Data augmentation optimization
- [x] Resolution increase to 640Ã—640 (66.6% mIoU)
- [x] Test-Time Augmentation (+1% boost)
- [ ] Cosine annealing LR (in progress)

### Phase 2: Object Detection ğŸ“‹
- [ ] Integrate YOLOv11 detection head
- [ ] Multi-task learning (shared backbone)
- [ ] Joint training (seg + det)
- [ ] Real-time optimization (30+ FPS target)

### Phase 3: Full Perception System ğŸ”®
- [ ] Depth estimation
- [ ] Lane detection
- [ ] Multi-camera fusion
- [ ] Temporal modeling (video)

**Goal**: Build a Tesla-like autonomous driving perception system ğŸš—ğŸ’¨

---

## ğŸ“š References

- **DeepLabV3+**: [Encoder-Decoder with Atrous Separable Convolution](https://arxiv.org/abs/1802.02611)
- **EfficientNet**: [Rethinking Model Scaling for CNNs](https://arxiv.org/abs/1905.11946)
- **Cityscapes**: [The Cityscapes Dataset](https://www.cityscapes-dataset.com/)
- **Focal Loss**: [Focal Loss for Dense Object Detection](https://arxiv.org/abs/1708.02002)

---

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) for details

---

## ğŸ™ Acknowledgments

- **Cityscapes team** for the dataset
- **segmentation_models_pytorch** for model implementations
- **Claude Code** for development assistance

---

<p align="center">
  <i>Part of an autonomous driving perception system project</i><br>
  <i>Next: Multi-task learning with object detection</i>
</p>
